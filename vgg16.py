# -*- coding: utf-8 -*-
"""VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eg8VdYIjJM1YxlIKQmjT7HkiYfCy42Uj
"""

from keras.applications.vgg16 import VGG16
# load the model
model = VGG16(weights='imagenet')

from google.colab import drive 
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import cv2
import os
import sys 
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from keras.preprocessing import image
from skimage.transform import resize
import tensorflow as tf
from keras.layers import Dense, Activation, Dropout, Bidirectional
from keras.layers.recurrent import LSTM
from keras.models import Sequential
from keras.optimizers import SGD
from keras import backend as K
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense,InputLayer
from keras.utils.vis_utils import plot_model
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing.image import img_to_array

#Load a video from file
video_input_file_path = ('/content/drive/My Drive/KBS/Object_detection/Everyday Objects In Macro.mp4')

#ORIGINAL YOUTUBE VIDEO
#https://youtu.be/K8rpo9e7tvg

#Output file
feature_output_file_path = ('/content/drive/My Drive/KBS/Object_detection/Frames/')

video = cv2.VideoCapture(video_input_file_path)
frameRate = video.get(5)

import math
count = 0
while(video.isOpened()):
    frameNum = video.get(1)
    ret, frame = video.read()
    if (ret != True):
        break
    if (frameNum % math.floor(frameRate) == 0):
        frameName = feature_output_file_path + "frame%d.jpg" % count;count+=1
        cv2.imwrite(frameName, frame)
video.release()
print ("Frame Capturing complete!")

#Checking if the capturing returned any files
current_dir = os.getcwd()
#Access the contents in the current directory
contents = os.listdir(current_dir) 
print("Available contents in %r: %s" % (current_dir, contents))

sample = plt.imread('/content/drive/My Drive/KBS/Object_detection/Frames/frame19.jpg')
plt.imshow(sample)

import pandas as pd
file = pd.read_csv('/content/drive/My Drive/KBS/Object_detection/Frames/mapping.csv')

X = [ ]

for frame_name in file.Image_ID:
    X.append(sample)

X = np.array(X)

y = file.Class
dummy_y = np_utils.to_categorical(y)

images = []
for i in range(0,X.shape[0]):
    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)
    images.append(a)
X = np.array(images)

X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

X_train = base_model.predict(X_train)
X_valid = base_model.predict(X_valid)
X_train.shape, X_valid.shape

X_train = X_train.reshape(208, 7*7*512)
X_valid = X_valid.reshape(90, 7*7*512)

train = X_train/X_train.max()
X_valid = X_valid/X_train.max()

"""**Building the model**"""

model = Sequential()
#Input layer
model.add(InputLayer((7*7*512,)))
#Hidden layer
model.add(Dense(units=1024, activation='sigmoid'))
model.add(Dense(3, activation='softmax'))

"""**Compiling the model**"""

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""**Training the model**"""

model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))

count = 0
video = cv2.VideoCapture(video_input_file_path)
frameRate = video.get(5)
x=1
while(video.isOpened()):
    frameId = video.get(1)
    ret, frame = video.read()
    if (ret != True):
        break
    if (frameId % math.floor(frameRate) == 0):
        filename ="Test%d.jpg" % count;count+=1
        cv2.imwrite(filename, frame)
video.release()
print ("Complete!")

test_file = pd.read_csv(('/content/drive/My Drive/KBS/Object_detection/Tests/test.csv'))

test_image = []
for img_name in test_file.Image_ID:
    test_image.append(sample)
testing_img = np.array(test_image)

test_image = []
for i in range(0,testing_img.shape[0]):
    t = resize(testing_img[i], preserve_range=True, output_shape=(224,224)).astype(int)
    test_image.append(t)
test_image = np.array(test_image)

#Extracting features from the images using pretrained model
test_image = base_model.predict(test_image)

# converting the images to 1-D form
test_image = test_image.reshape(186, 7*7*512)

# zero centered images
test_image = test_image/test_image.max()

predictions = model.predict_classes(test_image)

print("Bottle has been displayed for", predictions[predictions==2].shape[0], "seconds")

