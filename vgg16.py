# -*- coding: utf-8 -*-
"""VGG16 Video.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KX0iRFQv9DqL5rTL-7vP14euw6tjU3FS

# **R181600B - Sheunesu C Tazvivinga**
# **R181558W - Tafadzwa N Yemeke**
"""

from google.colab import drive 
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import cv2
import os
import sys 
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from keras.preprocessing import image
from skimage.transform import resize
import tensorflow as tf
from keras.layers import Dense, Activation, Dropout, Bidirectional
from keras.layers.recurrent import LSTM
from keras.models import Sequential
from keras.optimizers import SGD
from keras import backend as K
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense,InputLayer
from keras.utils.vis_utils import plot_model
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing.image import img_to_array

from keras.applications.vgg16 import VGG16
# load the model
model = VGG16(weights='imagenet')

#Load a video from file
video_input_file_path = ('/content/drive/My Drive/KBS/Object_detection/Everyday Objects In Macro.mp4')

#ORIGINAL YOUTUBE VIDEO
#https://youtu.be/K8rpo9e7tvg

#Output file
feature_output_file_path = ('/content/drive/My Drive/KBS/Object_detection/Frames/')

video = cv2.VideoCapture(video_input_file_path)
frameRate = video.get(5)

import math
count = 0
while(video.isOpened()):
    frameNum = video.get(1)
    ret, frame = video.read()
    if (ret != True):
        break
    if (frameNum % math.floor(frameRate) == 0):
        frameName = feature_output_file_path + "frame%d.jpg" % count;count+=1
        cv2.imwrite(frameName, frame)
video.release()
print ("Frame Capturing complete!")

#Checking if the capturing returned any files
current_dir = os.getcwd()
#Access the contents in the current directory
contents = os.listdir(current_dir) 
print("Available contents in %r: %s" % (current_dir, contents))

sample = plt.imread('/content/drive/My Drive/KBS/Object_detection/Frames/frame19.jpg')
plt.imshow(sample)

frames = '/content/drive/My Drive/KBS/Object_detection/Frames/*.jpg'

images = []
import glob
for filename in glob.glob(frames): 
  frame = image.load_img(filename, target_size=(224,224,224)) 
  images.append(frame)

for frame in images:
  frame_arr = image.img_to_array(frame)

frame_arr.shape

frame_arr = np.expand_dims(frame_arr, axis = 0)

# prepare the image for the VGG model
image = preprocess_input(frame_arr)

# predict the probability across all output classes
yhat = model.predict(image)

# convert the probabilities to class labels
from keras.applications.vgg16 import decode_predictions
label = decode_predictions(yhat)

# retrieve the most likely result, e.g. highest probability
label = label[0][0]

# print the classification
print('%s (%.2f%%)' % (label[1], label[2]*100))

